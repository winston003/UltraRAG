# UltraRAG DashScope ä½¿ç”¨æŒ‡å—

## ğŸ¯ æ¦‚è¿°

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•ä½¿ç”¨UltraRAGæ¡†æ¶é…åˆé˜¿é‡Œäº‘DashScope APIè¿›è¡Œæ–‡æœ¬å¤„ç†å’Œå‘é‡ç´¢å¼•æ„å»ºã€‚æˆ‘ä»¬æä¾›äº†å¤šä¸ªå·¥å…·æ¥æ»¡è¶³ä¸åŒçš„ä½¿ç”¨åœºæ™¯ã€‚

## ğŸ“ æ–‡ä»¶è¯´æ˜

### æ ¸å¿ƒè„šæœ¬
- **`process_dashscope.py`** - å•æ–‡ä»¶å¤„ç†è„šæœ¬ï¼ˆæ¨èï¼‰
- **`batch_process_dashscope.py`** - æ‰¹é‡å¤„ç†è„šæœ¬
- **`benchmark_dashscope.py`** - æ€§èƒ½æµ‹è¯•è„šæœ¬

### é…ç½®æ–‡ä»¶
- **`examples/dashscope_example.yaml`** - é…ç½®ç¤ºä¾‹
- **`README-text-processing.md`** - è¯¦ç»†æ–‡æ¡£

### è¾…åŠ©å·¥å…·
- **`process_simple.py`** - ç®€åŒ–ç‰ˆæœ¬ï¼ˆéœ€è¦OpenAIå…¼å®¹APIï¼‰
- **`process_and_index_text.py`** - æ ‡å‡†ç‰ˆæœ¬ï¼ˆéœ€è¦OpenAIå…¼å®¹APIï¼‰
- **`clean_index.py`** - ç´¢å¼•æ¸…ç†å·¥å…·

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# æ¿€æ´»UltraRAGç¯å¢ƒ
conda activate ultrarag

# è®¾ç½®é˜¿é‡Œäº‘APIå¯†é’¥
export ALI_EMBEDDING_API_KEY="your_aliyun_api_key_here"
```

### 2. å•æ–‡ä»¶å¤„ç†

```bash
# åŸºæœ¬ç”¨æ³•
python process_dashscope.py --input_file data/your_text.txt --overwrite

# è‡ªå®šä¹‰å‚æ•°
python process_dashscope.py \
  --input_file data/your_text.txt \
  --chunk_size 800 \
  --model text-embedding-v1 \
  --tokenizer bert-base-chinese \
  --overwrite
```

### 3. æ‰¹é‡å¤„ç†

```bash
# å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡æœ¬æ–‡ä»¶
python batch_process_dashscope.py --input_dir data/corpus --file_pattern "*.txt"

# é™åˆ¶å¤„ç†æ–‡ä»¶æ•°é‡
python batch_process_dashscope.py \
  --input_dir data/corpus \
  --file_pattern "*.txt" \
  --max_files 10 \
  --chunk_size 800 \
  --model text-embedding-v1
```

### 4. æ€§èƒ½æµ‹è¯•

```bash
# æµ‹è¯•ä¸åŒæ¨¡å‹çš„æ€§èƒ½
python benchmark_dashscope.py \
  --input_file data/word_chunk.txt \
  --models text-embedding-v1 text-embedding-v2 text-embedding-v3 \
  --chunk_sizes 400 800 1200 \
  --iterations 3
```

## ğŸ”§ å‚æ•°è¯´æ˜

### é€šç”¨å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `--input_file` | str | å¿…éœ€ | è¾“å…¥æ–‡æœ¬æ–‡ä»¶è·¯å¾„ |
| `--output_dir` | str | data/processed | è¾“å‡ºç›®å½• |
| `--chunk_size` | int | 800 | åˆ†å—å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰ |
| `--chunk_strategy` | str | recursive | åˆ†å—ç­–ç•¥ |
| `--model` | str | text-embedding-v1 | DashScopeæ¨¡å‹ |
| `--tokenizer` | str | bert-base-chinese | åˆ†è¯å™¨ |
| `--overwrite` | flag | False | è¦†ç›–ç°æœ‰æ–‡ä»¶ |

### æ‰¹é‡å¤„ç†å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `--input_dir` | str | å¿…éœ€ | è¾“å…¥ç›®å½•è·¯å¾„ |
| `--file_pattern` | str | *.txt | æ–‡ä»¶åŒ¹é…æ¨¡å¼ |
| `--max_files` | int | None | æœ€å¤§å¤„ç†æ–‡ä»¶æ•° |

### æ€§èƒ½æµ‹è¯•å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `--models` | list | v1,v2,v3 | æµ‹è¯•çš„æ¨¡å‹åˆ—è¡¨ |
| `--chunk_sizes` | list | 400,800,1200 | æµ‹è¯•çš„åˆ†å—å¤§å° |
| `--iterations` | int | 3 | æ¯ä¸ªæµ‹è¯•çš„é‡å¤æ¬¡æ•° |
| `--output_file` | str | benchmark_results.json | ç»“æœè¾“å‡ºæ–‡ä»¶ |

## ğŸ“Š æ”¯æŒçš„æ¨¡å‹

| æ¨¡å‹ | å‘é‡ç»´åº¦ | ç‰¹ç‚¹ | æ¨èåœºæ™¯ |
|------|----------|------|----------|
| `text-embedding-v1` | 1536 | é€šç”¨æ€§å¼ºï¼Œæ€§èƒ½ç¨³å®š | æ¨èä½¿ç”¨ |
| `text-embedding-v2` | 1536 | ä¼˜åŒ–ç‰ˆæœ¬ï¼Œè´¨é‡æ›´é«˜ | é«˜è´¨é‡è¦æ±‚ |
| `text-embedding-v3` | 1024 | è½»é‡çº§ï¼Œé€Ÿåº¦å¿« | å¤§è§„æ¨¡å¤„ç† |

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. åˆ†å—å¤§å°é€‰æ‹©
- **å°æ–‡æ¡£ï¼ˆ<1000å­—ç¬¦ï¼‰**: 400-600å­—ç¬¦
- **ä¸­ç­‰æ–‡æ¡£ï¼ˆ1000-5000å­—ç¬¦ï¼‰**: 800-1200å­—ç¬¦
- **å¤§æ–‡æ¡£ï¼ˆ>5000å­—ç¬¦ï¼‰**: 1200-2000å­—ç¬¦

### 2. æ‰¹é‡å¤„ç†ä¼˜åŒ–
- ä½¿ç”¨`--max_files`é™åˆ¶å¹¶å‘æ–‡ä»¶æ•°
- æ ¹æ®å†…å­˜å¤§å°è°ƒæ•´`--chunk_size`
- è€ƒè™‘ä½¿ç”¨`text-embedding-v3`æé«˜å¤„ç†é€Ÿåº¦

### 3. å†…å­˜ç®¡ç†
- å¤§æ–‡ä»¶å¤„ç†æ—¶ç›‘æ§å†…å­˜ä½¿ç”¨
- å¿…è¦æ—¶åˆ†æ‰¹å¤„ç†
- ä½¿ç”¨SSDå­˜å‚¨æé«˜I/Oæ€§èƒ½

## ğŸ” è¾“å‡ºæ–‡ä»¶è¯´æ˜

### å•æ–‡ä»¶å¤„ç†è¾“å‡º
```
data/processed/
â”œâ”€â”€ {filename}_chunks.jsonl    # åˆ†å—ç»“æœ
embedding/
â”œâ”€â”€ embedding_{filename}.npy   # åµŒå…¥å‘é‡
index/
â”œâ”€â”€ index_{filename}.index     # Faissç´¢å¼•
```

### æ‰¹é‡å¤„ç†è¾“å‡º
```
data/processed/
â”œâ”€â”€ file1_chunks.jsonl
â”œâ”€â”€ file2_chunks.jsonl
â”œâ”€â”€ ...
embedding/
â”œâ”€â”€ embedding_file1.npy
â”œâ”€â”€ embedding_file2.npy
â”œâ”€â”€ ...
index/
â”œâ”€â”€ index_file1.index
â”œâ”€â”€ index_file2.index
â”œâ”€â”€ ...
```

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **404é”™è¯¯**
   - æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®
   - ç¡®è®¤æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®
   - éªŒè¯ç½‘ç»œè¿æ¥

2. **å†…å­˜ä¸è¶³**
   - å‡å°`--chunk_size`
   - ä½¿ç”¨`--max_files`é™åˆ¶å¹¶å‘
   - è€ƒè™‘ä½¿ç”¨`text-embedding-v3`

3. **å¤„ç†é€Ÿåº¦æ…¢**
   - ä½¿ç”¨`text-embedding-v3`æ¨¡å‹
   - è°ƒæ•´åˆ†å—å¤§å°
   - æ£€æŸ¥ç½‘ç»œå»¶è¿Ÿ

4. **æ–‡ä»¶æƒé™é”™è¯¯**
   - æ£€æŸ¥è¾“å‡ºç›®å½•æƒé™
   - ç¡®ä¿æœ‰å†™å…¥æƒé™

### è°ƒè¯•æŠ€å·§

1. **å¯ç”¨è¯¦ç»†æ—¥å¿—**
   ```bash
   export ULTRA_RAG_LOG_LEVEL=DEBUG
   ```

2. **æµ‹è¯•APIè¿æ¥**
   ```bash
   python -c "
   import os
   from process_dashscope import DashScopeEmbedding
   client = DashScopeEmbedding(os.getenv('ALI_EMBEDDING_API_KEY'))
   result = await client.embed_texts(['æµ‹è¯•'])
   print('APIè¿æ¥æ­£å¸¸')
   "
   ```

3. **æ£€æŸ¥è¾“å‡ºæ–‡ä»¶**
   ```bash
   # æ£€æŸ¥åˆ†å—æ–‡ä»¶
   head -5 data/processed/*_chunks.jsonl
   
   # æ£€æŸ¥å‘é‡æ–‡ä»¶
   python -c "import numpy as np; print(np.load('embedding/embedding_word_chunk.npy').shape)"
   ```

## ğŸ“š é«˜çº§ç”¨æ³•

### 1. è‡ªå®šä¹‰åˆ†å—ç­–ç•¥

```python
# åœ¨process_dashscope.pyä¸­ä¿®æ”¹
chunk_result = await ToolCall.corpus.chunk_documents(
    chunk_strategy="semantic",  # ä½¿ç”¨è¯­ä¹‰åˆ†å—
    chunk_size=800,
    raw_data=raw_data['raw_data'],
    output_path=chunks_path,
    tokenizer_name_or_path="bert-base-chinese"
)
```

### 2. é›†æˆåˆ°ç°æœ‰é¡¹ç›®

```python
from process_dashscope import DashScopeEmbedding
import asyncio

async def process_text(text: str, model: str = "text-embedding-v1"):
    client = DashScopeEmbedding(
        api_key=os.getenv("ALI_EMBEDDING_API_KEY"),
        model=model
    )
    embeddings = await client.embed_texts([text])
    return embeddings[0]

# ä½¿ç”¨ç¤ºä¾‹
embedding = asyncio.run(process_text("ä½ çš„æ–‡æœ¬å†…å®¹"))
```

### 3. æ€§èƒ½ç›‘æ§

```python
import time
import psutil

def monitor_performance():
    start_time = time.time()
    start_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
    
    # æ‰§è¡Œå¤„ç†...
    
    end_time = time.time()
    end_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
    
    print(f"å¤„ç†æ—¶é—´: {end_time - start_time:.2f}s")
    print(f"å†…å­˜ä½¿ç”¨: {end_memory - start_memory:.2f}MB")
```

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·ï¼š

1. æŸ¥çœ‹é”™è¯¯æ—¥å¿—
2. æ£€æŸ¥ç¯å¢ƒé…ç½®
3. å‚è€ƒæ•…éšœæ’é™¤éƒ¨åˆ†
4. æäº¤Issueåˆ°é¡¹ç›®ä»“åº“

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªMITè®¸å¯è¯ï¼Œè¯¦è§LICENSEæ–‡ä»¶ã€‚
